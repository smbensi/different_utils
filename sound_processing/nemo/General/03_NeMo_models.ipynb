{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a NeMo model\n",
    "\n",
    "NeMo \"Models\" are comprised of a few key components . We'll go in the order (NN arch, Dataset + Data Loaders, Preprocessing + Postprocessing, Optimizer + scheduler , other infrastructure: tokenizers, LM configs, data augmentation, etc)\n",
    "\n",
    "To make this slightly challenging, let's port a model from the NLP domain. Transformers are all the rage, with BERT and his friends from Sesame street forming the core infrastructure for many NLP tasks.\n",
    "\n",
    "An excellent implementation of one such model - GPT - can be found in the `minGPT` repo https://github.com/karpathy/minGPT. We will attempt to port minGPT to NeMo "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction the Neural Network Architecture\n",
    "\n",
    "First, on the list - the neural network that forms the backbone of the NeMo model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-03-21 13:13:58 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nemo\n",
    "from nemo.core import NeuralModule\n",
    "from nemo.core import typecheck"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NeuralModule` is a subclass of `torch.nn.Module` and it brings with it a few additional functionalities \n",
    "It has the following capabilities:\n",
    "1. `Typing` it add supports for `Neural Type Checking` to the model. `Typing` is optional but quite useful\n",
    "2. `Serialization` the `OmegaConf` config dict and YAML config files . all `NeuralModules` inherhently supports serialization/deserialization from such config dict\n",
    "3. `FileIO` optional file serialization system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmptyModule(NeuralModule):\n",
    "\n",
    "    def forward(self):\n",
    "        print(\"Neural Module - hello world\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Module - hello world\n"
     ]
    }
   ],
   "source": [
    "x = MyEmptyModule()\n",
    "x()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural types\n",
    "\n",
    "Almost all NeMo components inherit the classs `Typing`. `Typing` is a simple class that adds 2 properties to the class that inherits it - `input_type` and `output_types`. A NeuralType is simply a semantic tensor. It contains info regarding the semantic shape and the tensor should hold, as well as the semantic info of what the tensor represents. \n",
    "\n",
    "So what semantic info does such a typed tensor contain? \n",
    "\n",
    "Across the DL domain, we often encounter cases where tensor shapes may match, but the semantics don't match at all. For example let's take a look at the following rank 3 tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[7, 9, 9, 0, 9]])\n",
      "embedding(x) : torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "# Case 1\n",
    "embedding = torch.nn.Embedding(num_embeddings=10, embedding_dim=30)\n",
    "x = torch.randint(high=10, size=(1,5))\n",
    "print(\"x: \", x)\n",
    "print(\"embedding(x) :\", embedding(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[[-1.6569],\n",
      "         [ 0.5693],\n",
      "         [-0.6563],\n",
      "         [ 0.5335],\n",
      "         [-0.5624]]])\n",
      "lstm(x) : torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "# Case 2\n",
    "lstm = torch.nn.LSTM(1, 30, batch_first=True)\n",
    "x = torch.randn(1, 5, 1)\n",
    "print(\"x: \", x)\n",
    "print(\"lstm(x) :\", lstm(x)[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to recognize that the 2 tensors do not represent the same semantic info is precisely why we utilize Neural Types. It contains the info of both the shape and the semantic concept of what that tensor represents. If we performed a neural type check between the 2 outputs of those tensors, it would raise an error saying semantically they were different things (they are `INCOMPATIBLE` with each other)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Types - Usage\n",
    "\n",
    "Neural Types are one of the core foundations of NeMo. While they are entirely *optional* and not instrusive, NeMo takes great care to support it so that there is no semantic incompatibility between components being used by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.core.neural_types import NeuralType\n",
    "from nemo.core.neural_types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModule(NeuralModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=10, embedding_dim=30)\n",
    "    \n",
    "    @typecheck()\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "    \n",
    "    @property\n",
    "    def input_types(self):\n",
    "        return {\n",
    "            'x': NeuralType(axes=('B','T'), elements_type=Index())\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def output_types(self):\n",
    "        return {\n",
    "            'y': NeuralType(axes=('B','T','C'), elements_type=EmbeddedTextType())\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss how we added  type checking support to the above class\n",
    "1. `forward` has a decorator `@typecheck()` on it\n",
    "2. `input_types` and `output_types` properties are defined\n",
    "\n",
    "Let's expand on each of the above steps\n",
    "- `@typecheck()` is a simple decorator that takes any class that inherits `Typing` (NeuralModule does this for us) and adds the 2 default properties of `input_types` and `output_types`, which by default return None\n",
    "\n",
    "The `@typecheck()` decorator's explicit use ensures that, by default, neural type checking is **disabled**. NeMo does not wish to intrude on the development process of models. So users can 'opt-in' to type checking by overriding the 2 properties. Therefore, the decorator ensures that users are not burdened with type checking before they wish to have it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
